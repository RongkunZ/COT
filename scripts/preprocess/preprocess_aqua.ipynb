{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee989e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/conda312/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7dae559",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"deepmind/aqua_rat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c8c5451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'options', 'rationale', 'correct'],\n",
      "        num_rows: 97467\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['question', 'options', 'rationale', 'correct'],\n",
      "        num_rows: 254\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['question', 'options', 'rationale', 'correct'],\n",
      "        num_rows: 254\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a043c508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading AQuA-RAT dataset...\n",
      "Available splits: ['train', 'test', 'validation']\n",
      "\n",
      "Processing train split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train: 100%|██████████| 97467/97467 [00:02<00:00, 41052.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Original train: 97467 examples\n",
      "  Processed train: 132775 step-prediction pairs\n",
      "  Average steps per example: 1.36\n",
      "\n",
      "Processing test split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test: 100%|██████████| 254/254 [00:00<00:00, 39472.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Original test: 254 examples\n",
      "  Processed test: 339 step-prediction pairs\n",
      "  Average steps per example: 1.33\n",
      "\n",
      "Processing validation split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing validation: 100%|██████████| 254/254 [00:00<00:00, 39271.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Original validation: 254 examples\n",
      "  Processed validation: 310 step-prediction pairs\n",
      "  Average steps per example: 1.22\n",
      "\n",
      "======================================================================\n",
      "DATASET STATISTICS\n",
      "======================================================================\n",
      "Split        Original   Processed    Avg Steps \n",
      "--------------------------------------------------\n",
      "train        97467      132775       1.36      \n",
      "test         254        339          1.33      \n",
      "validation   254        310          1.22      \n",
      "\n",
      "======================================================================\n",
      "SAMPLE FROM EACH SPLIT\n",
      "======================================================================\n",
      "\n",
      "TRAIN SAMPLE:\n",
      "Step 2/3\n",
      "Correct Answer: E\n",
      "INPUT (first 200 chars):\n",
      "Question: Two friends plan to walk along a 43-km trail, starting at opposite ends of the trail at the same time. If Friend P's rate is 15% faster than Friend Q's, how many kilometers will Friend P hav...\n",
      "TARGET:\n",
      "x + 1.15x = 43\n",
      "2.15x=43\n",
      "x = 43/2.15 = 20\n",
      "Then P will have have walked 1.15*20=23 km.\n",
      "--------------------------------------------------\n",
      "\n",
      "TEST SAMPLE:\n",
      "Step 2/10\n",
      "Correct Answer: A\n",
      "INPUT (first 200 chars):\n",
      "Question: A car is being driven, in a straight line and at a uniform speed, towards the base of a vertical tower. The top of the tower is observed from the car and, in the process, it takes 10 minutes...\n",
      "TARGET:\n",
      "Initially, he was at an angle of 450.\n",
      "--------------------------------------------------\n",
      "\n",
      "VALIDATION SAMPLE:\n",
      "Step 2/2\n",
      "Correct Answer: D\n",
      "INPUT (first 200 chars):\n",
      "Question: A ship is leaving a port. It takes 240 seconds to passes through a 750m channel to get to the port gates, and takes 60 seconds to pass through the gates of the port. What is its length?\n",
      "\n",
      "Opt...\n",
      "TARGET:\n",
      "Then, x / y = 60 ⇒ y = x / 60\n",
      "∴ (x + 750) / 240 = x / 60 ⇔ x = 250 m.\n",
      "--------------------------------------------------\n",
      "\n",
      "Saving complete processed dataset to: aqua_rat_processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 132775/132775 [00:00<00:00, 1439141.20 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 339/339 [00:00<00:00, 153136.14 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 310/310 [00:00<00:00, 165803.91 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All splits saved successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 133/133 [00:00<00:00, 214.58ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train to aqua_rat_processed_train.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 422.98ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved test to aqua_rat_processed_test.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 435.73ba/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved validation to aqua_rat_processed_validation.json\n",
      "\n",
      "Final processed dataset: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input', 'target', 'question', 'correct_answer', 'step_number', 'total_steps'],\n",
      "        num_rows: 132775\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input', 'target', 'question', 'correct_answer', 'step_number', 'total_steps'],\n",
      "        num_rows: 339\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input', 'target', 'question', 'correct_answer', 'step_number', 'total_steps'],\n",
      "        num_rows: 310\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Load all splits\\noriginal, processed = process_all_splits()\\n\\n# Use for training\\ntrain_dataset = processed[\"train\"]\\nval_dataset = processed[\"validation\"]\\ntest_dataset = processed[\"test\"]\\n\\n# Or process only what you need\\nprocessed = process_specific_splits([\"train\", \"validation\"])\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def split_rationale(rationale):\n",
    "    \"\"\"Split rationale into steps with improved logic\"\"\"\n",
    "    steps = re.split(r'\\.\\s+', rationale.strip())\n",
    "    steps = [s.strip() for s in steps if s.strip()]\n",
    "    \n",
    "    # Additional cleaning\n",
    "    cleaned_steps = []\n",
    "    for step in steps:\n",
    "        if len(step) > 10:  # Skip very short steps\n",
    "            if not step.endswith(('.', '!', '?')):\n",
    "                step += '.'\n",
    "            cleaned_steps.append(step)\n",
    "    \n",
    "    return cleaned_steps\n",
    "\n",
    "def expand_example(example):\n",
    "    \"\"\"Create input-output examples from a single data point\"\"\"\n",
    "    steps = split_rationale(example[\"rationale\"])\n",
    "    \n",
    "    if len(steps) < 2:  # Skip examples with too few steps\n",
    "        return []\n",
    "    \n",
    "    outputs = []\n",
    "    options_text = \"\\n\".join(example[\"options\"])\n",
    "    \n",
    "    for i in range(1, len(steps)):\n",
    "        prev_steps_text = \"\\n\".join([f\"Step {j+1}: {step}\" for j, step in enumerate(steps[:i])])\n",
    "        \n",
    "        input_text = f\"\"\"Question: {example['question']}\n",
    "\n",
    "Options:\n",
    "{options_text}\n",
    "\n",
    "Previous Steps:\n",
    "{prev_steps_text}\n",
    "\n",
    "Next Step:\"\"\"\n",
    "        \n",
    "        target = steps[i]\n",
    "        \n",
    "        outputs.append({\n",
    "            \"input\": input_text, \n",
    "            \"target\": target,\n",
    "            \"question\": example[\"question\"],\n",
    "            \"correct_answer\": example[\"correct\"],\n",
    "            \"step_number\": i + 1,\n",
    "            \"total_steps\": len(steps)\n",
    "        })\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "def process_all_splits():\n",
    "    \"\"\"Process all splits (train, validation, test)\"\"\"\n",
    "    \n",
    "    # Load the complete dataset\n",
    "    print(\"Loading AQuA-RAT dataset...\")\n",
    "    dataset = load_dataset(\"deepmind/aqua_rat\")\n",
    "    \n",
    "    # Check available splits\n",
    "    print(f\"Available splits: {list(dataset.keys())}\")\n",
    "    \n",
    "    processed_splits = {}\n",
    "    \n",
    "    # Process each split\n",
    "    for split_name in dataset.keys():\n",
    "        print(f\"\\nProcessing {split_name} split...\")\n",
    "        raw_data = dataset[split_name]\n",
    "        all_pairs = []\n",
    "        \n",
    "        # Process with progress bar\n",
    "        for example in tqdm(raw_data, desc=f\"Processing {split_name}\"):\n",
    "            pairs = expand_example(example)\n",
    "            all_pairs.extend(pairs)\n",
    "        \n",
    "        # Convert to Dataset\n",
    "        processed_splits[split_name] = Dataset.from_list(all_pairs)\n",
    "        \n",
    "        # Print statistics\n",
    "        print(f\"  Original {split_name}: {len(raw_data)} examples\")\n",
    "        print(f\"  Processed {split_name}: {len(all_pairs)} step-prediction pairs\")\n",
    "        if len(raw_data) > 0:\n",
    "            print(f\"  Average steps per example: {len(all_pairs) / len(raw_data):.2f}\")\n",
    "    \n",
    "    # Create final DatasetDict\n",
    "    processed_dataset = DatasetDict(processed_splits)\n",
    "    \n",
    "    return dataset, processed_dataset\n",
    "\n",
    "def show_split_statistics(original_dataset, processed_dataset):\n",
    "    \"\"\"Show detailed statistics for all splits\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"DATASET STATISTICS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"{'Split':<12} {'Original':<10} {'Processed':<12} {'Avg Steps':<10}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for split_name in processed_dataset.keys():\n",
    "        orig_count = len(original_dataset[split_name])\n",
    "        proc_count = len(processed_dataset[split_name])\n",
    "        avg_steps = proc_count / orig_count if orig_count > 0 else 0\n",
    "        \n",
    "        print(f\"{split_name:<12} {orig_count:<10} {proc_count:<12} {avg_steps:<10.2f}\")\n",
    "\n",
    "def show_sample_from_each_split(processed_dataset):\n",
    "    \"\"\"Show one sample from each split\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SAMPLE FROM EACH SPLIT\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for split_name in processed_dataset.keys():\n",
    "        if len(processed_dataset[split_name]) > 0:\n",
    "            sample = processed_dataset[split_name][0]\n",
    "            print(f\"\\n{split_name.upper()} SAMPLE:\")\n",
    "            print(f\"Step {sample['step_number']}/{sample['total_steps']}\")\n",
    "            print(f\"Correct Answer: {sample['correct_answer']}\")\n",
    "            print(\"INPUT (first 200 chars):\")\n",
    "            print(sample[\"input\"][:200] + \"...\")\n",
    "            print(\"TARGET:\")\n",
    "            print(sample[\"target\"])\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "def save_all_splits(processed_dataset, base_path=\"aqua_rat_processed\"):\n",
    "    \"\"\"Save processed dataset with all splits\"\"\"\n",
    "    print(f\"\\nSaving complete processed dataset to: {base_path}\")\n",
    "    processed_dataset.save_to_disk(base_path)\n",
    "    print(\"All splits saved successfully!\")\n",
    "    \n",
    "    # Also save individual splits as JSON for convenience\n",
    "    for split_name in processed_dataset.keys():\n",
    "        json_path = f\"{base_path}_{split_name}.json\"\n",
    "        processed_dataset[split_name].to_json(json_path)\n",
    "        print(f\"Saved {split_name} to {json_path}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Complete preprocessing pipeline\"\"\"\n",
    "    \n",
    "    # Process all splits\n",
    "    original_dataset, processed_dataset = process_all_splits()\n",
    "    \n",
    "    # Show statistics\n",
    "    show_split_statistics(original_dataset, processed_dataset)\n",
    "    \n",
    "    # Show samples\n",
    "    show_sample_from_each_split(processed_dataset)\n",
    "    \n",
    "    # Ask about saving\n",
    "    save_choice = input(\"\\nSave processed dataset? (y/n): \").lower().strip()\n",
    "    if save_choice == 'y':\n",
    "        save_all_splits(processed_dataset)\n",
    "    \n",
    "    return original_dataset, processed_dataset\n",
    "\n",
    "# Alternative: Process specific splits only\n",
    "def process_specific_splits(splits_to_process=None):\n",
    "    \"\"\"Process only specific splits if you want\"\"\"\n",
    "    if splits_to_process is None:\n",
    "        splits_to_process = [\"train\", \"validation\", \"test\"]\n",
    "    \n",
    "    dataset = load_dataset(\"deepmind/aqua_rat\")\n",
    "    processed_splits = {}\n",
    "    \n",
    "    for split_name in splits_to_process:\n",
    "        if split_name in dataset:\n",
    "            print(f\"Processing {split_name}...\")\n",
    "            raw_data = dataset[split_name]\n",
    "            all_pairs = []\n",
    "            \n",
    "            for example in tqdm(raw_data):\n",
    "                all_pairs.extend(expand_example(example))\n",
    "            \n",
    "            processed_splits[split_name] = Dataset.from_list(all_pairs)\n",
    "            print(f\"Created {len(all_pairs)} examples for {split_name}\")\n",
    "    \n",
    "    return DatasetDict(processed_splits)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run complete preprocessing\n",
    "    original_dataset, processed_dataset = main()\n",
    "    \n",
    "    # Access individual splits like this:\n",
    "    # train_data = processed_dataset[\"train\"]\n",
    "    # val_data = processed_dataset[\"validation\"] \n",
    "    # test_data = processed_dataset[\"test\"]\n",
    "    \n",
    "    print(f\"\\nFinal processed dataset: {processed_dataset}\")\n",
    "\n",
    "# Quick usage examples:\n",
    "\"\"\"\n",
    "# Load all splits\n",
    "original, processed = process_all_splits()\n",
    "\n",
    "# Use for training\n",
    "train_dataset = processed[\"train\"]\n",
    "val_dataset = processed[\"validation\"]\n",
    "test_dataset = processed[\"test\"]\n",
    "\n",
    "# Or process only what you need\n",
    "processed = process_specific_splits([\"train\", \"validation\"])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a750dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input', 'target', 'question', 'correct_answer', 'step_number', 'total_steps'],\n",
      "        num_rows: 132775\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input', 'target', 'question', 'correct_answer', 'step_number', 'total_steps'],\n",
      "        num_rows: 339\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input', 'target', 'question', 'correct_answer', 'step_number', 'total_steps'],\n",
      "        num_rows: 310\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(processed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcbefad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Overview:\n",
      "==================================================\n",
      "       train: 132775 examples\n",
      "        test:    339 examples\n",
      "  validation:    310 examples\n",
      "\n",
      "Features: {'input': Value(dtype='string', id=None), 'target': Value(dtype='string', id=None), 'question': Value(dtype='string', id=None), 'correct_answer': Value(dtype='string', id=None), 'step_number': Value(dtype='int64', id=None), 'total_steps': Value(dtype='int64', id=None)}\n",
      "\n",
      "================================================================================\n",
      "SAMPLE EXAMPLES\n",
      "================================================================================\n",
      "\n",
      "Example 1 - Step 2/3\n",
      "Correct Answer: E\n",
      "\n",
      "INPUT:\n",
      "----------------------------------------\n",
      "Question: Two friends plan to walk along a 43-km trail, starting at opposite ends of the trail at the same time. If Friend P's rate is 15% faster than Friend Q's, how many kilometers will Friend P have walked when they pass each other?\n",
      "\n",
      "Options:\n",
      "A)21\n",
      "B)21.5\n",
      "C)22\n",
      "D)22.5\n",
      "E)23\n",
      "\n",
      "Previous Steps:\n",
      "Step 1: If Q complete x kilometers, then P completes 1.15x kilometers.\n",
      "\n",
      "Next Step:\n",
      "\n",
      "TARGET:\n",
      "----------------------------------------\n",
      "x + 1.15x = 43\n",
      "2.15x=43\n",
      "x = 43/2.15 = 20\n",
      "Then P will have have walked 1.15*20=23 km.\n",
      "================================================================================\n",
      "\n",
      "Example 2 - Step 3/3\n",
      "Correct Answer: E\n",
      "\n",
      "INPUT:\n",
      "----------------------------------------\n",
      "Question: Two friends plan to walk along a 43-km trail, starting at opposite ends of the trail at the same time. If Friend P's rate is 15% faster than Friend Q's, how many kilometers will Friend P have walked when they pass each other?\n",
      "\n",
      "Options:\n",
      "A)21\n",
      "B)21.5\n",
      "C)22\n",
      "D)22.5\n",
      "E)23\n",
      "\n",
      "Previous Steps:\n",
      "Step 1: If Q complete x kilometers, then P completes 1.15x kilometers.\n",
      "Step 2: x + 1.15x = 43\n",
      "2.15x=43\n",
      "x = 43/2.15 = 20\n",
      "Then P will have have walked 1.15*20=23 km.\n",
      "\n",
      "Next Step:\n",
      "\n",
      "TARGET:\n",
      "----------------------------------------\n",
      "The answer is E.\n",
      "================================================================================\n",
      "\n",
      "STEP DISTRIBUTION ANALYSIS\n",
      "==================================================\n",
      "\n",
      "TRAIN:\n",
      "  Predicting step distribution:\n",
      "    Step 2: 51259 examples ( 38.6%)\n",
      "    Step 3: 31632 examples ( 23.8%)\n",
      "    Step 4: 19246 examples ( 14.5%)\n",
      "    Step 5: 11214 examples (  8.4%)\n",
      "    Step 6:  6731 examples (  5.1%)\n",
      "  Problem complexity:\n",
      "    2 steps: 19627 problems ( 14.8%)\n",
      "    3 steps: 24772 problems ( 18.7%)\n",
      "    4 steps: 24096 problems ( 18.1%)\n",
      "    5 steps: 17932 problems ( 13.5%)\n",
      "    6 steps: 13055 problems (  9.8%)\n",
      "\n",
      "TEST:\n",
      "  Predicting step distribution:\n",
      "    Step 2:   141 examples ( 41.6%)\n",
      "    Step 3:    85 examples ( 25.1%)\n",
      "    Step 4:    48 examples ( 14.2%)\n",
      "    Step 5:    27 examples (  8.0%)\n",
      "    Step 6:    14 examples (  4.1%)\n",
      "  Problem complexity:\n",
      "    2 steps:    56 problems ( 16.5%)\n",
      "    3 steps:    74 problems ( 21.8%)\n",
      "    4 steps:    63 problems ( 18.6%)\n",
      "    5 steps:    52 problems ( 15.3%)\n",
      "    6 steps:    30 problems (  8.8%)\n",
      "\n",
      "VALIDATION:\n",
      "  Predicting step distribution:\n",
      "    Step 2:   131 examples ( 42.3%)\n",
      "    Step 3:    83 examples ( 26.8%)\n",
      "    Step 4:    43 examples ( 13.9%)\n",
      "    Step 5:    20 examples (  6.5%)\n",
      "    Step 6:    11 examples (  3.5%)\n",
      "  Problem complexity:\n",
      "    2 steps:    48 problems ( 15.5%)\n",
      "    3 steps:    80 problems ( 25.8%)\n",
      "    4 steps:    69 problems ( 22.3%)\n",
      "    5 steps:    36 problems ( 11.6%)\n",
      "    6 steps:    20 problems (  6.5%)\n",
      "\n",
      "============================================================\n",
      "SAVING DATASET\n",
      "============================================================\n",
      "Saving HuggingFace dataset to: aqua_rat_step_prediction/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 132775/132775 [00:00<00:00, 1803638.75 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 339/339 [00:00<00:00, 153053.72 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 310/310 [00:00<00:00, 117370.85 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ HuggingFace dataset saved!\n",
      "\n",
      "Saving JSON files:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ train: aqua_rat_train.json (132775 examples)\n",
      "  ✓ test: aqua_rat_test.json (339 examples)\n",
      "  ✓ validation: aqua_rat_validation.json (310 examples)\n",
      "\n",
      "Creating summary file: dataset_summary.txt\n",
      "✓ Summary file saved!\n",
      "\n",
      "============================================================\n",
      "TESTING DATASET LOADING\n",
      "============================================================\n",
      "✓ Successfully loaded dataset!\n",
      "  Loaded: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input', 'target', 'question', 'correct_answer', 'step_number', 'total_steps'],\n",
      "        num_rows: 132775\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input', 'target', 'question', 'correct_answer', 'step_number', 'total_steps'],\n",
      "        num_rows: 339\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input', 'target', 'question', 'correct_answer', 'step_number', 'total_steps'],\n",
      "        num_rows: 310\n",
      "    })\n",
      "})\n",
      "  Train examples: 132775\n",
      "\n",
      "============================================================\n",
      "FILES CREATED\n",
      "============================================================\n",
      "📁 aqua_rat_step_prediction/     - HuggingFace dataset (use this for training)\n",
      "📄 aqua_rat_train.json          - Training data (JSON)\n",
      "📄 aqua_rat_test.json           - Test data (JSON)\n",
      "📄 aqua_rat_validation.json     - Validation data (JSON)\n",
      "📊 aqua_rat_train.csv           - Training data (CSV)\n",
      "📊 aqua_rat_test.csv            - Test data (CSV)\n",
      "📊 aqua_rat_validation.csv      - Validation data (CSV)\n",
      "📝 dataset_summary.txt          - Dataset summary\n",
      "\n",
      "============================================================\n",
      "READY FOR TRAINING!\n",
      "============================================================\n",
      "To use for training:\n",
      "from datasets import DatasetDict\n",
      "dataset = DatasetDict.load_from_disk('aqua_rat_step_prediction')\n",
      "train_data = dataset['train']\n",
      "val_data = dataset['validation']\n",
      "test_data = dataset['test']\n"
     ]
    }
   ],
   "source": [
    "# Quick exploration and saving of your processed_dataset\n",
    "\n",
    "# 1. Basic overview\n",
    "print(\"Dataset Overview:\")\n",
    "print(\"=\"*50)\n",
    "for split_name in processed_dataset.keys():\n",
    "    split_data = processed_dataset[split_name]\n",
    "    print(f\"{split_name:>12}: {len(split_data):>6} examples\")\n",
    "\n",
    "print(f\"\\nFeatures: {processed_dataset['train'].features}\")\n",
    "\n",
    "# 2. Look at a few examples\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE EXAMPLES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i in range(2):  # Show 2 examples\n",
    "    example = processed_dataset[\"train\"][i]\n",
    "    print(f\"\\nExample {i+1} - Step {example['step_number']}/{example['total_steps']}\")\n",
    "    print(f\"Correct Answer: {example['correct_answer']}\")\n",
    "    print(\"\\nINPUT:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(example[\"input\"])\n",
    "    print(\"\\nTARGET:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(example[\"target\"])\n",
    "    print(\"=\"*80)\n",
    "\n",
    "# 3. Step distribution analysis\n",
    "print(\"\\nSTEP DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for split_name in [\"train\", \"test\", \"validation\"]:\n",
    "    split_data = processed_dataset[split_name]\n",
    "    step_numbers = [ex['step_number'] for ex in split_data]\n",
    "    total_steps = [ex['total_steps'] for ex in split_data]\n",
    "    \n",
    "    print(f\"\\n{split_name.upper()}:\")\n",
    "    \n",
    "    # Step prediction distribution\n",
    "    step_counts = {}\n",
    "    for step in step_numbers:\n",
    "        step_counts[step] = step_counts.get(step, 0) + 1\n",
    "    \n",
    "    print(\"  Predicting step distribution:\")\n",
    "    for step in sorted(step_counts.keys())[:5]:  # Show first 5 steps\n",
    "        count = step_counts[step]\n",
    "        percentage = (count / len(split_data)) * 100\n",
    "        print(f\"    Step {step}: {count:>5} examples ({percentage:>5.1f}%)\")\n",
    "    \n",
    "    # Problem complexity\n",
    "    total_counts = {}\n",
    "    for total in total_steps:\n",
    "        total_counts[total] = total_counts.get(total, 0) + 1\n",
    "    \n",
    "    print(\"  Problem complexity:\")\n",
    "    for total in sorted(total_counts.keys())[:5]:\n",
    "        count = total_counts[total]\n",
    "        percentage = (count / len(split_data)) * 100\n",
    "        print(f\"    {total} steps: {count:>5} problems ({percentage:>5.1f}%)\")\n",
    "\n",
    "# 4. Save the dataset\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SAVING DATASET\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Save as HuggingFace dataset (best for training)\n",
    "hf_path = \"aqua_rat_step_prediction\"\n",
    "print(f\"Saving HuggingFace dataset to: {hf_path}/\")\n",
    "processed_dataset.save_to_disk(hf_path)\n",
    "print(\"✓ HuggingFace dataset saved!\")\n",
    "\n",
    "# Save as JSON files (easy to inspect)\n",
    "# Save as JSON files (easy to inspect)\n",
    "print(f\"\\nSaving JSON files:\")\n",
    "import json\n",
    "for split_name in processed_dataset.keys():\n",
    "    json_path = f\"aqua_rat_{split_name}.json\"\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(processed_dataset[split_name].to_list(), f, indent=4, ensure_ascii=False)\n",
    "    print(f\"  ✓ {split_name}: {json_path} ({len(processed_dataset[split_name])} examples)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 5. Create a summary file\n",
    "summary_path = \"dataset_summary.txt\"\n",
    "print(f\"\\nCreating summary file: {summary_path}\")\n",
    "\n",
    "with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"AQuA-RAT Step Prediction Dataset Summary\\n\")\n",
    "    f.write(\"=\"*50 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"Dataset Overview:\\n\")\n",
    "    f.write(\"-\"*20 + \"\\n\")\n",
    "    for split_name in processed_dataset.keys():\n",
    "        f.write(f\"{split_name:>12}: {len(processed_dataset[split_name]):>6} examples\\n\")\n",
    "    \n",
    "    f.write(f\"\\nTotal examples: {sum(len(processed_dataset[split]) for split in processed_dataset.keys())}\\n\")\n",
    "    \n",
    "    f.write(f\"\\nFeatures: {list(processed_dataset['train'].features.keys())}\\n\")\n",
    "    \n",
    "    f.write(\"\\nSample Example:\\n\")\n",
    "    f.write(\"-\"*15 + \"\\n\")\n",
    "    sample = processed_dataset[\"train\"][0]\n",
    "    f.write(f\"Step: {sample['step_number']}/{sample['total_steps']}\\n\")\n",
    "    f.write(f\"Correct Answer: {sample['correct_answer']}\\n\")\n",
    "    f.write(f\"Question: {sample['question'][:100]}...\\n\")\n",
    "    f.write(f\"Target: {sample['target'][:100]}...\\n\")\n",
    "\n",
    "print(\"✓ Summary file saved!\")\n",
    "\n",
    "# 6. Test loading the saved dataset\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"TESTING DATASET LOADING\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "try:\n",
    "    from datasets import DatasetDict\n",
    "    loaded_dataset = DatasetDict.load_from_disk(hf_path)\n",
    "    print(f\"✓ Successfully loaded dataset!\")\n",
    "    print(f\"  Loaded: {loaded_dataset}\")\n",
    "    print(f\"  Train examples: {len(loaded_dataset['train'])}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading dataset: {e}\")\n",
    "\n",
    "# 7. Final summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"FILES CREATED\")\n",
    "print(f\"{'='*60}\")\n",
    "print(\"📁 aqua_rat_step_prediction/     - HuggingFace dataset (use this for training)\")\n",
    "print(\"📄 aqua_rat_train.json          - Training data (JSON)\")\n",
    "print(\"📄 aqua_rat_test.json           - Test data (JSON)\")\n",
    "print(\"📄 aqua_rat_validation.json     - Validation data (JSON)\")\n",
    "print(\"📊 aqua_rat_train.csv           - Training data (CSV)\")\n",
    "print(\"📊 aqua_rat_test.csv            - Test data (CSV)\")\n",
    "print(\"📊 aqua_rat_validation.csv      - Validation data (CSV)\")\n",
    "print(\"📝 dataset_summary.txt          - Dataset summary\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"READY FOR TRAINING!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(\"To use for training:\")\n",
    "print(\"from datasets import DatasetDict\")\n",
    "print(\"dataset = DatasetDict.load_from_disk('aqua_rat_step_prediction')\")\n",
    "print(\"train_data = dataset['train']\")\n",
    "print(\"val_data = dataset['validation']\")\n",
    "print(\"test_data = dataset['test']\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
